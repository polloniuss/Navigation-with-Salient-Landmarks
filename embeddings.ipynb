{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "487555bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "\n",
    "import os\n",
    "import base64\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "import json\n",
    "import spacy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import operator\n",
    "import seaborn\n",
    "import cv2\n",
    "from nltk.corpus import wordnet as wn\n",
    "from num2words import num2words\n",
    "import csv\n",
    "\n",
    "import torch\n",
    "import logging\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16eff1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(file):\n",
    "    \n",
    "    list_values = []\n",
    "    \n",
    "    with open(file) as f:\n",
    "        reader = csv.reader(f, delimiter='\\n')\n",
    "        for line in reader:\n",
    "            for sent in line:\n",
    "                list_values.append(sent)\n",
    "        f.close()\n",
    "    \n",
    "    return list_values\n",
    "    \n",
    "frcnn_data = get_data(\"frcnn_emb.csv\")\n",
    "desc_data = get_data(\"desc_emb.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d643fe62",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at CPUAllocator.cpp:71] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 94673922336 bytes. Error code 12 (Cannot allocate memory)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 61>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m Score: \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(sentences[i], sentences[j], pair[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m#return output_emb\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m \u001b[43mget_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdesc_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfrcnn_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36mget_embeddings\u001b[0;34m(data_np, data_frcnn)\u001b[0m\n\u001b[1;32m     39\u001b[0m embeddings_f \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode(input_emb_f, convert_to_tensor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m#Compute cosine-similarits\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m cosine_scores \u001b[38;5;241m=\u001b[39m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcos_sim\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings_f\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m#Output the pairs with their score\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(embeddings_np)):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sentence_transformers/util.py:42\u001b[0m, in \u001b[0;36mcos_sim\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m     40\u001b[0m a_norm \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mnormalize(a, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     41\u001b[0m b_norm \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mnormalize(b, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_norm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at CPUAllocator.cpp:71] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 94673922336 bytes. Error code 12 (Cannot allocate memory)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4370eb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#word embeddings to match synonyms\n",
    "#run the similarity between object labels VS noun phrases\n",
    "# https://www.sbert.net/docs/usage/semantic_textual_similarity.html\n",
    "\n",
    "def get_embeddings(data_np,data_frcnn):\n",
    "    \"\"\"Gets embeddings from dataset.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_np : list\n",
    "        A list of sentences from R2R dataset.\n",
    "        \n",
    "    data_frcnn : list\n",
    "        A list of attributes and objects from FRCNN.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    output_emb : list\n",
    "        List of sentences and their embedding.\n",
    "    \"\"\"\n",
    "    \n",
    "    data_nouns = []\n",
    "        \n",
    "    for sent in data_np:\n",
    "        sent = sent.split()\n",
    "        for idx, ele in enumerate(sent):\n",
    "            if ele.isdigit():\n",
    "                ele = num2words(ele)\n",
    "                sent[idx] = ele\n",
    "           \n",
    "        data_nouns.append(\" \".join(sent))\n",
    "            \n",
    "    \n",
    "    output_emb = []\n",
    "    input_emb_np = data_nouns\n",
    "    input_emb_f = data_frcnn\n",
    "    \n",
    "    embeddings_np = model.encode(input_emb_np, convert_to_tensor=True)\n",
    "    embeddings_f = model.encode(input_emb_f, convert_to_tensor=True)\n",
    "    \n",
    "    #Compute cosine-similarits\n",
    "    cosine_scores = util.cos_sim(embeddings_np, embeddings_f)\n",
    "    \n",
    "    #Output the pairs with their score\n",
    "    for i in range(len(embeddings_np)):\n",
    "        print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(embeddings_np[i], embeddings_f[i], cosine_scores[i][i]))\n",
    "    \n",
    "    #Find the pairs with the highest cosine similarity scores\n",
    "    pairs = []\n",
    "    for i in range(len(cosine_scores)-1):\n",
    "        for j in range(i+1, len(cosine_scores)):\n",
    "            pairs.append({'index': [i, j], 'score': cosine_scores[i][j]})\n",
    "    #Sort scores in decreasing order\n",
    "    pairs = sorted(pairs, key=lambda x: x['score'], reverse=True)\n",
    "    for pair in pairs[0:10]:\n",
    "        i, j = pair['index']\n",
    "        print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(sentences[i], sentences[j], pair['score']))\n",
    "    \n",
    "    #return output_emb\n",
    "\n",
    "get_embeddings(desc_data,frcnn_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
